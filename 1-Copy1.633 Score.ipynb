{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import geopy\n",
    "from geopy import distance\n",
    "from geopy.distance import vincenty\n",
    "# from tqdm import tqdm\n",
    "# tqdm.pandas()\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from dateutil import parser\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "import numpy as np\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "# from skopt.space import Real\n",
    "import matplotlib.colors as clt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "from scipy.stats import kurtosis, skew, moment\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "%matplotlib inline\n",
    "from keras.layers import Dense\n",
    "# Change pandas viewing options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "import zipfile\n",
    "from keras.models import Sequential\n",
    "# zf = zipfile.ZipFile('train.csv') # having First.csv zipped file.\n",
    "# df = pd.read_csv(zf.open('First.csv'))\n",
    "# zf.namelist()\n",
    "\n",
    "import os\n",
    "# print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_features(X):\n",
    "    strain = []\n",
    "    strain.append(X.mean())\n",
    "    strain.append(X.median())\n",
    "    strain.append(X.std())\n",
    "    strain.append(X.min())\n",
    "    strain.append(X.max())\n",
    "    strain.append(X.kurtosis())\n",
    "    strain.append(X.skew())\n",
    "    strain.append(X.ptp())\n",
    "    strain.append(X.var())\n",
    "#     strain.append(X.mad())\n",
    "    strain.append(np.quantile(X, 0.01))\n",
    "    strain.append(np.quantile(X, 0.05))\n",
    "    zc=np.fft.fft(X)\n",
    "    realFFT = np.real(zc)\n",
    "    imagFFT = np.imag(zc)\n",
    "    strain.append(realFFT.mean())\n",
    "    strain.append(realFFT.std())\n",
    "    strain.append(realFFT.max())\n",
    "    strain.append(realFFT.min())\n",
    "    strain.append(imagFFT.mean())\n",
    "    strain.append(imagFFT.std())\n",
    "    strain.append(imagFFT.max())\n",
    "    strain.append(imagFFT.min())\n",
    "    strain.append(moment([X], moment=0, axis=1, nan_policy='omit'))\n",
    "    strain.append(moment([X], moment=1, axis=1, nan_policy='omit'))\n",
    "    strain.append(moment([X], moment=2, axis=1, nan_policy='omit'))\n",
    "    strain.append(moment([X], moment=3, axis=1, nan_policy='omit'))\n",
    "    strain.append(moment([X], moment=4, axis=1, nan_policy='omit'))\n",
    "    strain.append(moment([X], moment=5, axis=1, nan_policy='omit'))\n",
    "\n",
    "\n",
    "\n",
    "    strain.append((np.clip([X],0,1000)).mean())\n",
    "    return pd.Series(strain)\n",
    "\n",
    "# final.describe()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv.zip', iterator=True, chunksize=200_000, dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
    "# train=pd.read_csv('../input/train.csv', iterator=True, chunksize=150_000, dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train1 = pd.DataFrame()\n",
    "y_train1= pd.Series()\n",
    "for df in train:\n",
    "    df=df.drop(df[df.acoustic_data >400].index)\n",
    "\n",
    "    ch = gen_features(df['acoustic_data'])\n",
    "    X_train1 = X_train1.append(ch, ignore_index=True)\n",
    "    y_train1 = y_train1.append(pd.Series(df['time_to_failure'].values[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train1.ix[:,19].min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train1, y_train1, train_size=0.9, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pool = Pool(X_train_scaled, y_binary)\n",
    "model=CatBoostRegressor(iterations=1000, depth=3, learning_rate=0.1, loss_function='MAE',boosting_type='Plain')\n",
    "model.fit(X_train, y_train, silent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred=(model.predict(X_test))\n",
    "mean_absolute_error(y_test, y_pred, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv', index_col='seg_id')\n",
    "X_test = pd.DataFrame()\n",
    "\n",
    "# prepare test data\n",
    "for seg_id in submission.index:\n",
    "    seg = pd.read_csv('test/' + seg_id + '.csv')\n",
    "\n",
    "    ch = gen_features(seg['acoustic_data'])\n",
    "    X_test = X_test.append(ch, ignore_index=True)\n",
    "\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['time_to_failure'] = y_hat\n",
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the modules we'll need\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "\n",
    "# function that takes in a dataframe and creates a text link to  \n",
    "# download it (will only work for files < 2MB or so)\n",
    "def create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n",
    "    csv = df.to_csv()\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "create_download_link(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns=['mean','median','std','min','max','kurt','skew','ptp','var','q.01','q.05','Rmean','Rstd','Rmax','Rmin','Imean','Istd','Imax','Imin','0M','1M','2M','3M','4M','5M','thres']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_importance_df=pd.DataFrame()\n",
    "fold_importance_df['Feature']=X_test.columns\n",
    "feature_importance_df=pd.DataFrame()\n",
    "fold_importance_df[\"importance\"]=model.feature_importances_[:len(X_train1.columns)]\n",
    "feature_importance_df=pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n",
    "        .groupby(\"Feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:200].index)\n",
    "best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
    "\n",
    "# plt.figure(figsize=(14,26))\n",
    "sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n",
    "plt.title('LightGBM Features (averaged over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
